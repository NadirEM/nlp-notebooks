# NLP Notebooks

[Fine-tune ALBERT for sentence-pair classification](https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb) | How to fine-tune an ALBERT model or another BERT-based model for the sentence-pair classification task | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb)

The main features of this tutorial are :

[1] End-to-end ML implementation (training, validation, prediction, evaluation)

[2] Easy adaptability to your own datasets

[3] Facilitation of quick experiments with other BERT-based models (BERT, ALBERT, ...)

[4] Quick training with limited computational resources (mixed-precision, gradient accumulation, ...)

[5] Multi-GPU execution

[6] Threshold choice for the classification decision (not necessarily 0.5)

[7] Freeze BERT layers and only update the classification layer weights or update all the weights

[8] Reproducible results with seed settings
